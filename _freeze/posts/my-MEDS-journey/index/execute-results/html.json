{
  "hash": "2c9ca6d92a746baf4fa7e0eb959ad4a8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"My Journey Through MEDS: A Year of Environmental Data Science\"\nauthor: \"Lucian Scher\"\ndate: today\nformat: \n  closeread-html:\n    css: ../../styles.scss\n    embed-resources: true\n    toc: true\n    toc-depth: 3\nexecute:\n  echo: false\n  warning: false\n  message: false\n---\n\n\n\n# Introduction: A Year of Transformation\n\n{#cr-intro}\nWhen I began the Master of Environmental Data Science (MEDS) program at UC Santa Barbara's Bren School, I knew I was stepping into a world where environmental science meets cutting-edge computational methods. What I didn't fully anticipate was how profoundly this one-year intensive program would reshape my understanding of data, science, and the complex environmental challenges facing our planet.\n\nThis journey—from foundational mathematics to advanced machine learning, from geospatial analysis to policy evaluation—culminated in a capstone project that seeks to identify sustainable pathways for hydropower development in a net-zero future. Through this closeread document, I invite you to explore the knowledge, skills, and insights I've gained across thirteen core courses and a transformative capstone experience.\n\n:::{.cr-section}\n:::{#cr-intro}\n<!-- ![PLACEHOLDER: Photo of Bren School or UCSB campus - wide landscape shot showing the beautiful coastal setting where MEDS takes place](images/meds-campus.jpg) -->\n\nThe MEDS program is designed as an intensive, one-year professional degree that bridges environmental science with data science. As a student, I was immersed in a collaborative environment supported by expert faculty from the Bren School and the National Center for Ecological Analysis & Synthesis (NCEAS). The program's philosophy centers on using data science to advance solutions to environmental problems—a mission that resonated deeply with my own goals.\n:::\n:::\n\n## The Program Structure\n\nThe MEDS curriculum is organized into four quarters, each building upon the previous:\n\n- **Summer Session B**: Foundational skills in mathematics, workflows, Python, and scientific programming\n- **Fall Quarter**: Working with environmental datasets, statistics, geospatial analysis, and ethics\n- **Winter Quarter**: Modeling environmental systems, data visualization, policy evaluation, and capstone initiation\n- **Spring Quarter**: Databases, machine learning, and capstone completion\n\nEach course was designed not just to teach technical skills, but to foster a deep understanding of how data science can be responsibly applied to environmental challenges.\n\n---\n\n# Summer Session B: Building Foundations\n\n{#cr-summer}\nThe summer session was an intensive introduction to the tools and thinking that would underpin everything to come. Four courses in rapid succession: Essential Math, Analytical Workflows, Python Programming, and Scientific Programming Essentials.\n\n:::{.cr-section}\n## EDS 212: Essential Math for Environmental Data Science\n\n*Instructor: Carmen Galaz García*\n\nMathematics is the language of data science. This course refreshed fundamental skills in algebra, calculus, differential equations, linear algebra, and logical operations—all essential for understanding the models and methods we would use throughout the program.\n\n<!-- ![PLACEHOLDER: Mathematical visualization showing calculus concepts or distribution functions](images/eds212-math.jpg) -->\n\n**Key Concepts:**\n- Multivariate functions and their applications\n- Derivative and integral calculus for environmental modeling\n- Differential equations for dynamic systems\n- Linear algebra for data transformations\n- Logical operations for data filtering and conditional analysis\n\nThe course emphasized that mathematical understanding isn't just about computation—it's about developing intuition for how environmental systems behave and how we can represent them mathematically.\n:::\n\n:::{.cr-section}\n## EDS 214: Analytical Workflows and Scientific Reproducibility\n\n*Instructor: Max Czapanskiy*\n\nReproducibility isn't optional in science—it's fundamental. This course taught me how to create workflows that are transparent, shareable, and reproducible.\n\n<!-- ![PLACEHOLDER: Screenshot of a well-organized GitHub repository showing project structure, README, and workflow documentation](images/eds214-workflow.jpg) -->\n\n**Core Skills:**\n1. **Automation**: Scripting every step of an analytical workflow\n2. **Modularity**: Organizing workflow components for reusability\n3. **Documentation**: Clearly documenting components and their relationships\n4. **Scaling**: Adapting workflows for computational performance and large datasets\n5. **Collaboration**: Working in teams to develop shared workflows\n\nThe course instilled in me the importance of thinking about analysis as a process, not just a result. Every script, every data transformation, every visualization should be traceable and reproducible.\n:::\n\n:::{.cr-section}\n## EDS 217: Python for Environmental Data Science\n\n*Instructor: Kelly Caylor*\n\nPython became my primary tool for data manipulation and analysis. This course covered foundational programming concepts through the lens of environmental data.\n\n<!-- ![PLACEHOLDER: Python code visualization or Jupyter notebook showing data analysis workflow](images/eds217-python.jpg) -->\n\n**What I Learned:**\n- Data structures (lists, dictionaries, DataFrames)\n- Programming basics (loops, conditionals, functions)\n- Data cleaning, subsetting, aggregation, and transformation\n- Data visualization with matplotlib and seaborn\n- Application to environmental problem-solving\n\nThe course emphasized that Python isn't just a programming language—it's a tool for thinking about data. Learning to manipulate data programmatically opened up possibilities for analysis that would have been impossible with spreadsheet software.\n:::\n\n:::{.cr-section}\n## EDS 221: Scientific Programming Essentials\n\n*Instructor: Max Czapanskiy*\n\nBuilding on Python foundations, this course delved deeper into scientific programming practices using both R and Python.\n\n<!-- ![PLACEHOLDER: Code comparison showing R vs Python approaches to the same analysis](images/eds221-scientific.jpg) -->\n\n**Advanced Topics:**\n- Structured programming and algorithm development\n- Flow control and program logic\n- Advanced data input-output and representation\n- Functions and object-oriented programming\n- Documentation, testing, and debugging\n\nThis course taught me that good scientific code is readable, testable, and maintainable. It's not enough for code to work—it needs to be understandable to others (and to your future self).\n:::\n\n---\n\n# Fall Quarter: Deepening Analysis\n\n{#cr-fall}\nFall quarter brought four courses that expanded my analytical toolkit: Working with Environmental Datasets, Statistics, Geospatial Analysis, and Data Ethics. These courses showed me how to apply foundational skills to real environmental data and questions.\n\n:::{.cr-section}\n## EDS 220: Working with Environmental Datasets\n\n*Instructors: Carmen Galaz García, Annie Adams*\n\nEnvironmental data comes in many forms: field measurements, station data, remote sensing products, climate model projections. This course taught me how to work with this diversity.\n\n<!-- ![PLACEHOLDER: Visualization showing different types of environmental data: satellite imagery, time series, spatial grids](images/eds220-datasets.jpg) -->\n\n**Key Skills:**\n- Evaluating data collection and quality control methods\n- Working with time-series and spatial information\n- Accessing cloud computing databases and environmental data repositories\n- Basic workflows for selecting, obtaining, and visualizing datasets\n- Best practices for reliable data intercomparisons\n\nI developed a tutorial Jupyter notebook for a use case of my choice, learning to navigate the complexities of real environmental datasets. The course emphasized that understanding data provenance and quality is as important as the analysis itself.\n:::\n\n:::{.cr-section}\n## EDS 222: Statistics for Environmental Data Science\n\n*Instructor: Max Czapanskiy*\n\nStatistics provides the framework for making inferences from data. This course covered fundamental statistical concepts and their application to environmental questions.\n\n<!-- ![PLACEHOLDER: Statistical visualization showing distributions, regression lines, confidence intervals](images/eds222-stats.jpg) -->\n\n**Core Topics:**\n\n### Random Variables and Distributions\n- Binomial distributions for discrete data (presence/absence)\n- Normal distributions for continuous data\n- Gamma distributions for positive continuous variables (durations, concentrations)\n- Understanding parameters and how they control distribution shape\n\n### Linear Regression\n- Fitting lines to points and understanding residuals\n- Quality of fit: R² and variance explained\n- Population vs. sample regression models\n- Assumptions about data generating processes (DGP)\n\n### Categorical and Continuous Predictors\n- Categorical coefficients as intercepts\n- Additive vs. interactive models\n- Confounding variables and backdoor paths\n- DAGs (Directed Acyclic Graphs) for causal relationships\n\n### Inference\n- Permutation and bootstrapping\n- Hypothesis testing and confidence intervals\n- Normal approximations of sampling distributions\n- Linear regression inference\n\nThe course emphasized that statistics isn't just about running tests—it's about understanding the assumptions behind methods and choosing appropriate approaches for your data and question.\n:::\n\n:::{.cr-section}\n## EDS 223: Geospatial Analysis and Remote Sensing\n\n*Instructor: Annie Adams*\n\nSpatial data is fundamental to environmental science. This course introduced geographic information science and remote sensing through deep understanding of spatial data models.\n\n<!-- ![PLACEHOLDER: Beautiful map showing geospatial analysis results - perhaps land cover classification or spatial patterns](images/eds223-geospatial.jpg) -->\n\n**Spatial Data Models:**\n\n### Vectors (Discrete Data)\n- Points, lines, and polygons\n- Spatial subsetting and topological relationships\n- Filtering, clipping, and spatial operations\n\n### Rasters (Continuous Data)\n- Grid-based data representation\n- Map algebra: local, focal, zonal, and global operations\n- Aggregating and resampling raster data\n\n### Coordinate Systems\n- Understanding CRS (Coordinate Reference Systems)\n- Geographic vs. projected coordinate systems\n- Datums and map projections\n- Transforming between coordinate systems\n\n### Remote Sensing\n- Passive vs. active remote sensing\n- LiDAR and RADAR fundamentals\n- Energy-matter interactions (absorption, reflectance, scattering)\n- Image resolutions: spatial, temporal, spectral, radiometric\n- Land cover classification (supervised and unsupervised)\n\nThe course taught me that spatial data requires special consideration—spatial autocorrelation, coordinate systems, and scale all matter profoundly for analysis and interpretation.\n:::\n\n:::{.cr-section}\n## EDS 242: Ethics and Bias in Environmental Data Science\n\n*Instructor: Jayajit Chakraborty*\n\nData science isn't neutral. This course examined ethical considerations in collecting, using, and reporting environmental data, and how to recognize and account for biases.\n\n<!-- ![PLACEHOLDER: Infographic or visualization showing types of data bias and their impacts](images/eds242-ethics.jpg) -->\n\n**Types of Data Bias:**\n1. **Confirmation Bias**: Seeing what you want to see\n2. **Historical Bias**: Deceived by context of data creators\n3. **Selection Bias**: Non-representative samples (coverage, non-response, sampling, recall)\n4. **Survivorship Bias**: Including only surviving data points\n5. **Availability Bias**: Recording data by ease of access\n6. **Reporting Bias**: Dataset frequency doesn't reflect real-world frequency\n7. **Observer Bias**: Subjectivity of the observer\n8. **Geographic Data Bias**: Where data comes from matters\n9. **Urban vs. Rural Bias**: Spatial representation disparities\n\nThe course emphasized that recognizing bias isn't enough—we must actively work to mitigate it and be transparent about limitations in our data and methods. Ethical data science requires constant vigilance and critical reflection.\n:::\n\n---\n\n# Winter Quarter: Advanced Applications\n\n{#cr-winter}\nWinter quarter brought advanced courses in modeling, visualization, and policy evaluation, while also launching the capstone project. These courses showed me how to apply data science to complex environmental systems and policy questions.\n\n:::{.cr-section}\n## EDS 230: Modeling Environmental Systems\n\n*Instructor: Christina Tague*\n\nModels are simplifications of reality designed to answer questions. This course covered both selecting and applying existing models and designing new ones.\n\n<!-- ![PLACEHOLDER: Conceptual model diagram showing inputs, processes, and outputs of an environmental system](images/eds230-models.jpg) -->\n\n**Model Types:**\n- **Stochastic vs. Deterministic**: Probability-based vs. fixed outcomes\n- **Lumped vs. Spatially Distributed**: Single point vs. spatial variation\n- **Static vs. Dynamic**: Single time point vs. evolving through time\n- **Abstract vs. Physically Based**: Data-driven (ML) vs. mechanism-based\n\n**Key Concepts:**\n- Conceptual models: diagrams of system relationships\n- Sensitivity analysis: understanding parameter uncertainty\n- Dynamic models: differential equations and state space trajectories\n- Feedback loops: positive (runaway growth) and negative (dampening)\n- Stability: stable, unstable, and chaotic systems\n\nThe course emphasized that \"all models are wrong, but some are useful.\" The goal isn't perfect representation—it's useful simplification that helps answer specific questions.\n:::\n\n:::{.cr-section}\n## EDS 240: Data Visualization and Communication\n\n*Instructors: Samantha Shanny-Csik, Annie Adams*\n\nEffective communication is central to data science. This course focused on creating responsible, accessible, and visually compelling visualizations.\n\n<!-- ![PLACEHOLDER: Gallery of beautiful data visualizations created during the course](images/eds240-viz.jpg) -->\n\n**The Grammar of Graphics (ggplot2):**\n1. **Data**: Tidy format + aesthetic mappings\n2. **Geometric objects**: Type of plot\n3. **Statistical transformations**: Algorithms for new values\n4. **Position adjustments**: Handling overlaps\n5. **Coordinate systems**: Cartesian, polar, flipped\n6. **Facets**: Subplots for data subsets\n\n**Additional Layers:**\n- Labels: titles, axis labels, legends\n- Annotations: textual labels and highlights\n- Scales: color scales, axis ticks\n- Themes: Customizing non-data elements\n- Layout: Combining multiple plots\n\nThe course also introduced **closeread-html** for creating interactive, scrollytelling visualizations—the format you're reading now! This tool allows for sticky elements, triggers, and dynamic highlighting that guide readers through complex narratives.\n:::\n\n:::{.cr-section}\n## EDS 241: Environmental Policy Evaluation\n\n*Instructors: Adam Garber, Annie Adams*\n\nCausal inference is crucial for evaluating environmental policies. This course presented state-of-the-art program evaluation techniques to identify and measure causal effects.\n\n<!-- ![PLACEHOLDER: Visualization showing difference-in-differences analysis or regression discontinuity design](images/eds241-policy.jpg) -->\n\n**Research Designs:**\n\n### Experimental Methods\n- **Randomized Controlled Trials**: Random assignment to treatment/control\n- **Natural Experiments**: Real-world situations mimicking random assignment\n\n### Quasi-Experimental Methods\n- **Difference-in-Differences (DiD)**: Leveraging time trends with parallel trends assumption\n- **Regression Discontinuity Design (RDD)**: Utilizing arbitrary thresholds/cutoffs\n- **Instrumental Variables (IV)**: Exploiting indirect influences\n\n### Other Methods\n- **Fixed Effects**: The within estimator for panel data\n- **Matching Methods**: Creating apples-to-apples comparisons\n\n**Key Concepts:**\n- Potential outcomes framework: Yi(1) vs. Yi(0)\n- Average Treatment Effect (ATE) vs. Average Treatment for the Treated (ATT)\n- Selection bias and omitted variable bias\n- Panel data: repeated measures over time\n- Robust standard errors for heteroscedasticity\n\nThe course emphasized that correlation isn't causation. Design-based research methods, combined with careful statistical analysis, allow us to make stronger causal claims about policy impacts.\n:::\n\n:::{.cr-section}\n## EDS 411A: Capstone Project (Part 1)\n\n*Instructor: Carmen Galaz García*\n\nThe capstone project is the culmination of the MEDS program—a real-world application of data science to an environmental problem, conducted in collaboration with external clients.\n\n<!-- ![PLACEHOLDER: Team photo or project kickoff meeting with capstone team and clients](images/eds411a-capstone.jpg) -->\n\n**Project Structure:**\n- **10-12 hours per week** dedicated to capstone work\n- **Design and Implementation Plan (DIP)**: First draft due week 5, final due week 10\n- **Faculty Review**: 12-minute presentation of DIP\n- **Collaboration**: Working with clients, advisors, and team members\n\n**Ten Simple Rules for Collaborative Data Science Teams:**\n1. Lead from the front\n2. Seeing is believing\n3. Skin in the game\n4. Comfort through clarity\n5. All codes lead to Rome\n6. People first\n7. Empowerment through ownership\n8. Open science\n9. Safe learning spaces\n10. Have fun\n\nThe capstone isn't just about technical skills—it's about professional development, collaboration, and applying everything learned to a meaningful environmental challenge.\n:::\n\n---\n\n# Spring Quarter: Integration and Completion\n\n{#cr-spring}\nSpring quarter brought the final core courses and capstone completion. These courses integrated everything learned and prepared us for professional practice.\n\n:::{.cr-section}\n## EDS 213: Databases and Data Management\n\n*Instructors: Julien Brun, Greg Janée, Annie Adams, Renata Curty*\n\nData management is foundational to reproducible science. This course taught relational database structure, SQL, and data archiving.\n\n<!-- ![PLACEHOLDER: Database schema diagram or ERD showing relationships between tables](images/eds213-databases.jpg) -->\n\n**Key Topics:**\n- Relational database structure and schemas\n- Data relationships and normalization\n- SQL for creating and querying databases\n- Metadata concepts and standards\n- Archiving data products on repositories\n- Making data available to broader community\n\nThe course emphasized that good data management isn't just about storage—it's about making data findable, accessible, interoperable, and reusable (FAIR principles).\n:::\n\n:::{.cr-section}\n## EDS 232: Machine Learning in Environmental Science\n\n*Instructors: Carmen Galaz García, Annie Adams*\n\nMachine learning helps process big, complex data and extract knowledge. This course provided a broad introduction to ML and statistical pattern recognition.\n\n<!-- ![PLACEHOLDER: Machine learning visualization showing decision trees, random forests, or neural network architecture](images/eds232-ml.jpg) -->\n\n**Topics Covered:**\n- **Supervised Learning**: Decision trees, random forests, support vector machines, neural networks\n- **Unsupervised Learning**: Clustering, dimensionality reduction, deep learning\n- Applications framed within environmental science\n- Programming in R and Python for advanced scientific programming\n\nThe course emphasized that machine learning is a tool, not a solution. Understanding when and how to apply ML methods, and interpreting results responsibly, is crucial for environmental applications.\n:::\n\n:::{.cr-section}\n## EDS 411B: Capstone Project (Part 2)\n\n*Instructor: Carmen Galaz García*\n\nThe second quarter of capstone focused on completing all project plans and deliverables, developing the project repository and technical documentation, and presenting research to a general audience.\n\n<!-- ![PLACEHOLDER: Final capstone presentation slide or project deliverable screenshot](images/eds411b-completion.jpg) -->\n\n**Deliverables:**\n- Completed project implementation\n- Public GitHub repository with all code and workflows\n- Technical documentation\n- Interactive web application (Shiny app)\n- Final presentation to general audience\n- Project repository adhering to open science principles\n\nThe capstone experience integrated everything learned throughout the program: technical skills, collaboration, communication, and ethical practice. It was both a culmination and a beginning—preparing us for professional careers in environmental data science.\n:::\n\n---\n\n# The Capstone: Hydropower's Low-Hanging Fruits\n\n{#cr-capstone}\nMy capstone project, conducted with teammates Leela Dixit, Sofia Sarak, and Vedika Shirtekar, represents the integration of everything I learned in MEDS. In collaboration with Dr. Jeff Opperman (WWF Global Science) and Dr. Rafael Schmitt (UCSB), we developed a framework to identify sustainable pathways for hydropower development.\n\n:::{.cr-section}\n## The Environmental Challenge\n\n<!-- ![PLACEHOLDER: Global map showing river fragmentation or hydropower dam locations](images/capstone-challenge.jpg) -->\n\nHydropower presents a fundamental dilemma: it's a low-carbon, flexible energy source that can support climate action, but dams fragment rivers, disrupt ecosystems, and impact communities. Current projections suggest we may need to double global hydropower capacity by 2050 to meet climate objectives, but 63% of the world's longest rivers are already fragmented.\n\n**The Core Question:**\nCan we identify \"low-hanging fruits\"—future dam sites that combine lower environmental impact with energy system benefits—to reconcile climate goals with river conservation?\n\nThis question isn't just academic. It's urgent. As Dr. Opperman wrote in his letter of support: \"Current high-level policy debates about hydropower's role in addressing future climate and energy challenges are not adequately considering the potential tradeoffs with hydropower expansion.\"\n:::\n\n:::{.cr-section}\n## Project Objectives\n\nOur project aimed to analyze sustainability constraints for expanding future hydropower by:\n\n1. **Identifying topological relationships**: Determining where future dams sit relative to existing dams (upstream, downstream, within cascades, or blocking free-flowing rivers)\n\n2. **Screening for conflicts**: Identifying \"fatal flaws\" such as conflicts with protected areas or population centers\n\n3. **Categorizing sustainability**: Classifying at least 3,700 global dam sites into sustainability categories\n\n4. **Quantifying capacity**: Calculating generation capacity (in gigawatts) within each category\n\n<!-- ![PLACEHOLDER: Schematic diagram showing the four sustainability categories (SI Figure 1 from proposal)](images/capstone-categories.jpg) -->\n\nThe goal was to enable investors and policymakers to judge the environmental impact associated with different levels of hydropower expansion, closing a critical knowledge gap in energy systems planning.\n:::\n\n:::{.cr-section}\n## The Data Science Approach\n\n<!-- ![PLACEHOLDER: Workflow diagram showing the analytical pipeline from raw data to final outputs](images/capstone-workflow.jpg) -->\n\n**Key Datasets:**\n1. **HydroRivers**: Global vectorized river network with metadata (discharge, etc.)\n2. **GRAND**: Global Reservoir and Dam dataset (7,300 existing large dams)\n3. **FHReD**: Future Hydropower and Reservoir Data (~3,700 future dam sites)\n4. **Protected Planet**: Protected area boundaries for conflict screening\n5. **WorldPop**: Population density data for conflict screening\n\n**Analytical Tools:**\n- **sf package**: Vector data and geospatial operations\n- **tidygraph package**: Network topology and connectivity analysis\n- **riverconn package**: River fragmentation indices\n- **Shiny package**: Interactive web applications\n\nAll datasets are vectorized and publicly available, enabling reproducible analysis on personal computers by processing one river basin at a time.\n:::\n\n:::{.cr-section}\n## Deliverables\n\n### Deliverable 1: Scripted Workflow\n\nA reproducible workflow to:\n- Identify topological location of future dams relative to existing dams\n- Screen for conflicts (\"fatal flaws\") with protected areas and population centers\n- Enable future expansion with additional data and screening criteria\n\n<!-- ![PLACEHOLDER: Screenshot of workflow code or GitHub repository structure](images/capstone-d1.jpg) -->\n\n### Deliverable 2: Updated Dataset\n\nAn enhanced dataset of future dams with:\n- Sustainability category classification (within cascade, upstream/downstream, undammed river, or fatally flawed)\n- Increase in river fragmentation index for each future dam\n- Generation capacity by category\n\n<!-- ![PLACEHOLDER: Data visualization showing dam categorization results or capacity by category](images/capstone-d2.jpg) -->\n\n### Deliverable 3: Interactive Web Viewer\n\nA Shiny application enabling users to:\n- Visualize results spatially\n- Filter and analyze by country, capacity range, or sustainability category\n- Explore dam locations and their impacts\n\n<!-- ![PLACEHOLDER: Screenshot of Shiny app interface showing interactive map and filters](images/capstone-d3.jpg) -->\n:::\n\n:::{.cr-section}\n## The Research Context\n\nOur work builds on important prior research:\n\n**Schmitt & Rosa (2024)** found that:\n- Global demand for hydropower (+38%) and irrigation storage (+73%) by 2050\n- Europe and South Asia face \"double deficits\" where neither energy nor water needs can be met by dams alone\n- 43% of current hydropower relies on multipurpose dams, creating conflicts\n- 60-64% of remaining technical potential needed just to meet basic projections\n\n**Grill et al. (2019)** mapped the world's free-flowing rivers, showing that:\n- Only 1/3 of major rivers remain free-flowing\n- Current dam building would fragment many remaining free-flowing rivers\n- Large tropical rivers supporting productive fisheries and deltas are particularly at risk\n\n**Schmitt et al. (2019)** on the Mekong:\n- Strategic dam placement can achieve same energy with 4% sediment loss vs. 79% under business-as-usual\n- The 3S Basin (10% of land area) provides 25% of sediment—losing it is catastrophic\n- Vietnam gets 0% of new hydropower but bears 100% of geomorphic costs\n\n<!-- ![PLACEHOLDER: Map of Mekong River Basin showing dam locations and sediment flow](images/capstone-mekong.jpg) -->\n:::\n\n:::{.cr-section}\n## Key Insights and Broader Impact\n\n<!-- ![PLACEHOLDER: Final results visualization showing global patterns of sustainable vs. high-impact dam sites](images/capstone-results.jpg) -->\n\n**What Our Analysis Reveals:**\n\n1. **Spatial Patterns**: Some regions (Latin America, South Asia) have hydropower surplus relative to decarbonization needs, while others face deficits, especially where sites are in ecologically sensitive or populated areas.\n\n2. **Cascade Benefits**: Dams built within existing cascades have much lower impacts than new dams on free-flowing rivers—this is the \"low-hanging fruit.\"\n\n3. **Conflict Identification**: Many proposed sites conflict with protected areas or population centers—these \"fatal flaws\" should be avoided.\n\n4. **Capacity by Category**: Understanding how much capacity exists in each sustainability category enables energy system planners to make informed decisions.\n\n**Broader Impact:**\n\nOur methods contribute to:\n- **Policy Dialogues**: Enabling global and national policy discussions based on quantitative data\n- **Energy Systems Modeling**: Straightforward integration of sustainability criteria into energy planning\n- **Accessibility**: Allowing local NGOs and citizens without resources to engage in science-informed debates\n- **Avoiding Detrimental Effects**: Helping minimize negative impacts on rivers and communities\n\nThe workflow is designed to be adaptable, allowing for public expansion with additional indicators and downscaling to inform local decisions.\n:::\n\n:::{.cr-section}\n## Technical Challenges and Solutions\n\n<!-- ![PLACEHOLDER: Code snippet or technical diagram showing network analysis approach](images/capstone-technical.jpg) -->\n\n**Challenge 1: Network Topology**\nUnderstanding spatial relationships between dams in river networks required network analysis. We used `tidygraph` and `sfnetworks` to model river connectivity and identify cascade relationships.\n\n**Challenge 2: Scale**\nProcessing global datasets with millions of river reaches required careful spatial subsetting and processing by basin. We developed workflows that could run on personal computers by processing one basin at a time.\n\n**Challenge 3: Reproducibility**\nCreating a workflow that others could use and modify required extensive documentation, modular code design, and clear data dependencies. We followed best practices from EDS 214 (workflows) throughout.\n\n**Challenge 4: Visualization**\nCommunicating complex spatial and categorical information required thoughtful design. We used principles from EDS 240 (visualization) to create clear, accessible visualizations in our Shiny app.\n:::\n\n:::{.cr-section}\n## Reflection: What I Learned\n\n<!-- ![PLACEHOLDER: Personal reflection photo or team working together](images/capstone-reflection.jpg) -->\n\nThe capstone project was the most challenging and rewarding experience of the MEDS program. It required:\n\n- **Integration**: Bringing together skills from every course—statistics, geospatial analysis, modeling, visualization, ethics, and more\n\n- **Collaboration**: Working effectively with teammates, clients, and advisors, following the \"Ten Simple Rules\" for collaborative data science\n\n- **Problem-Solving**: Tackling real-world challenges with no clear answers, requiring creativity and persistence\n\n- **Communication**: Translating technical work for diverse audiences—scientists, policymakers, and the public\n\n- **Responsibility**: Working on a project with real-world implications, requiring careful consideration of ethics and impacts\n\nThe capstone wasn't just about applying what I learned—it was about learning how to learn, how to adapt, and how to contribute meaningfully to environmental problem-solving.\n:::\n\n---\n\n# Additional Courses: Specialized Skills\n\n{#cr-additional}\nBeyond the core curriculum, I took two additional courses that expanded my toolkit:\n\n:::{.cr-section}\n## EDS 231: Text and Sentiment Analysis for Environmental Problems\n\n*Instructor: Mateo Robbins*\n\nThis course covered foundations and applications of natural language processing for environmental data sources.\n\n<!-- ![PLACEHOLDER: Visualization showing text analysis results, word clouds, or sentiment analysis outputs](images/eds231-text.jpg) -->\n\n**Applications:**\n- Social media feeds (e.g., Twitter) for environmental sentiment\n- Agency reports and policy documents\n- Text processing and classification\n- Semantics and natural language parsing\n\nThe course showed me how text data can provide insights into public perception, policy discourse, and environmental communication.\n:::\n\n:::{.cr-section}\n## EDS 296-1S: Intro to Shiny - Building Reactive Apps and Dashboards\n\n*Instructor: Samantha Shanny-Csik*\n\nThis short course taught the fundamentals of building interactive web applications with R Shiny.\n\n<!-- ![PLACEHOLDER: Screenshot of a Shiny app interface](images/eds296-shiny.jpg) -->\n\n**Key Skills:**\n- Understanding reactivity\n- Customizing user interfaces\n- Best practices and workflows\n- Deploying apps via shinyapps.io\n\nThis course directly supported our capstone project, enabling us to create the interactive web viewer for our dam sustainability analysis.\n:::\n\n---\n\n# Conclusion: A Year of Growth\n\n{#cr-conclusion}\nLooking back on this year, I'm struck by how much I've learned—not just technical skills, but ways of thinking about data, science, and environmental challenges.\n\n:::{.cr-section}\n<!-- ![PLACEHOLDER: Final reflection image - perhaps a view from Bren School or a symbolic image representing the journey](images/conclusion-reflection.jpg) -->\n\n**Technical Skills:**\n- Programming in R and Python\n- Statistical analysis and inference\n- Geospatial analysis and remote sensing\n- Machine learning and modeling\n- Data visualization and communication\n- Database management and workflows\n\n**Professional Skills:**\n- Collaborative data science\n- Reproducible workflows\n- Ethical data practice\n- Policy evaluation methods\n- Scientific communication\n\n**Personal Growth:**\n- Confidence in tackling complex problems\n- Appreciation for interdisciplinary collaboration\n- Commitment to open science and reproducibility\n- Understanding of the responsibility that comes with data science\n\nThe MEDS program has prepared me not just to analyze environmental data, but to do so responsibly, collaboratively, and effectively. The capstone project, in particular, showed me how all these pieces fit together to address real-world environmental challenges.\n\nAs I move forward in my career, I carry with me not just technical skills, but a framework for thinking about how data science can contribute to environmental solutions. The challenges we face—climate change, biodiversity loss, resource management, environmental justice—require the kind of interdisciplinary, data-driven approach that MEDS embodies.\n\nThank you for joining me on this journey through the Master of Environmental Data Science program. The work continues, but the foundation is strong.\n:::\n\n---\n\n# Acknowledgments\n\nThis journey was made possible by:\n\n- **The Bren School faculty** who designed and taught this exceptional program\n- **NCEAS** for providing collaborative research support\n- **My capstone team**: Leela Dixit, Sofia Sarak, and Vedika Shirtekar\n- **Our capstone clients**: Dr. Jeff Opperman (WWF) and Dr. Rafael Schmitt (UCSB)\n- **My MEDS cohort** for collaboration and community\n- **The broader environmental data science community** for open science and knowledge sharing\n\n---\n\n*This document was created using Quarto's closeread-html format, which enables interactive, scrollytelling narratives. The styling matches my personal website's SCSS theme, creating a cohesive visual experience.*\n\n*All course materials, code, and project deliverables are available in public GitHub repositories, following open science principles.*\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}